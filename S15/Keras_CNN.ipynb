{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copia de Keras-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIGyXAgeq_O"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9PLbF8Veq_O"
      },
      "source": [
        "Cargamos los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2P_PR0-eq_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8198614d-ce63-4d42-eb2a-e3019e88815b"
      },
      "source": [
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-hbRx6ieq_O"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 1, 28, 28)\n",
        "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 1, 28, 28)\n",
        "    input_shape = (1, 28, 28)\n",
        "else:\n",
        "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 28, 28, 1)\n",
        "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)\n",
        "    \n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxKV_ZPheq_O"
      },
      "source": [
        "Convertimos las etiquetas de train y tes en modo categórico\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTtbszNeq_O"
      },
      "source": [
        "train_labels = tensorflow.keras.utils.to_categorical(mnist_train_labels, 10)\n",
        "test_labels = tensorflow.keras.utils.to_categorical(mnist_test_labels, 10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfvwl5r9eq_O"
      },
      "source": [
        "Visualizamos una imagen y su etiquetado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jorsQDBqeq_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "b3991e61-f4c5-43c0-97c5-bc486cede934"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_sample(num):\n",
        "    #Print the one-hot array of this sample's label \n",
        "    print(train_labels[num])  \n",
        "    #Print the label converted back to a number\n",
        "    label = train_labels[num].argmax(axis=0)\n",
        "    #Reshape the 768 values to a 28x28 image\n",
        "    image = train_images[num].reshape([28,28])\n",
        "    plt.title('Sample: %d  Label: %d' % (num, label))\n",
        "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "    plt.show()\n",
        "    \n",
        "display_sample(1254)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efYJTNAieq_P"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "# 64 3x3 kernels\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# Reduce by taking the max of each 2x2 block\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Dropout to avoid overfitting\n",
        "model.add(Dropout(0.25))\n",
        "# Flatten the results to one dimension for passing into our final layer\n",
        "model.add(Flatten())\n",
        "# A hidden layer to learn with\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Another dropout\n",
        "model.add(Dropout(0.5))\n",
        "# Final categorization from 0-9 with softmax\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOrLwRXxeq_P"
      },
      "source": [
        "Resumiendo el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMo6v5YXeq_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5956d329-5926-4ade-ad28-fb82e185914b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKCgLlD8eq_P"
      },
      "source": [
        "Debido a la categorización múltiple se utilizará como función de pérdida \"categorical_crossentropy\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhsnXiNEeq_P"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPoWdk08eq_P"
      },
      "source": [
        "Para acelerar el entrenamiento se utilizarán lotes de 32 imágenes.\n",
        "\n",
        "## Warning\n",
        "\n",
        "  Cada epoch puede demorar mas de 20 minutos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybSSMru9eq_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b997f8-2942-4a64-867a-af465730ba09"
      },
      "source": [
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=32,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTUKUpcoeq_P",
        "outputId": "11efd39c-c016-4450-b4aa-6fe5be036441"
      },
      "source": [
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.034441117036675316\n",
            "Test accuracy: 0.9908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm7jsEe4eq_P"
      },
      "source": [
        "Para reducir los tiempos de procesamiento conviene trabajar con computación distribuidad con múltiples GPU's, en especial para aplicaciones donde un punto porcentual de mejora puede valer la pena como el caso de entrenamiento de redes neuronales para autos autónomos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDixin43eq_P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}